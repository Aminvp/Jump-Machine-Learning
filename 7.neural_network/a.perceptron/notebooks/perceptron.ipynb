{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d333515a",
   "metadata": {},
   "source": [
    "<h1 align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "ูพุฑุณูพุชุฑูู\n",
    "</font>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed20bff",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "ููุฏูู ู ุตูุฑุช ูุณุฆูู\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    ุจู ฺฉ ุชูุฑู ุงุณุงุณ ุงุฒ ูพุงูโุงโุชุฑู ูุจุงุญุซ ุดุจฺฉูโูุง ุนุตุจ ุฎูุด ุขูุฏุฏ! ุฏุฑ ุงู ุชูุฑู ุฑูฺฉุฑุฏ ูุชูุงูุช ุฑุง ุฏุฑ ูพุด ุฎูุงูู ฺฏุฑูุช ู ูุตุฏ ุฏุงุฑู ุณุงุฎุชุงุฑ ูพุฑุณูพุชุฑูู ู ุงูฺฏูุฑุชู ุขููุฒุด ุขู ุฑุง ฺฉู ุฏุฑ ุฏุฑุณูุงููโูุง ูพุดู ุขููุฎุชุฏ ูุณุชููุงู ูพุงุฏูโุณุงุฒ ฺฉูู. ฺฉุฏููุณ ุฏุฑ ุงู ุณุทุญ ุจู ุดูุง ฺฉูฺฉ ุฎูุงูุฏ ฺฉุฑุฏ ฺฉู ุจู ุดฺฉู ุนูู ุฏุฑฺฉ ุนููโุชุฑ ุงุฒ ูุญููโ ฺฉุงุฑ ุงู ูุฏู ูพุฏุง ฺฉูุฏ ู ุฏุฑ ุขูุฏู ูุฒ ููฺฏุงู ููุงุฌู ุจุง ูุฏูโูุง ูุฎุชูู ุดุจฺฉูโูุง ุนุตุจ ูุงุฏุฑ ุจู ุชุญูู ุขุณุงูโุชุฑ ุณุงุฎุชุงุฑ ุขูโูุง ุจุงุดุฏ. ูพุณ ุงุฒ ุทุฑุงุญ ูพุฑุณูพุชุฑููุ ุขู ุฑุง ุฑู ูุฌููุนูโุฏุงุฏูโ ูุดููุฑ <i>ฺฏูโูุง ุฒูุจู (iris)</i> ุขููุฒุด ุฏุงุฏู ู ุนููฺฉุฑุฏ ุฏู ุฑูุด ูุฎุชูู ุขููุฒุด ูพุฑุณูพุชุฑููุ ุนู ูุงุนุฏูโ ูพุฑุณูพุชุฑูู ู ูุงุนุฏูโ ุฏูุชุง ุฑุง ุจุฑ ุฑู ุงู ูุฌููุนูโุฏุงุฏู ุงุฑุฒุงุจ ุฎูุงูู ฺฉุฑุฏ.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af1784",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "ูุงุฑุฏ ฺฉุฑุฏู ฺฉุชุงุจุฎุงููโูุง ููุฑุฏ ูุงุฒ\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    ุงุจุชุฏุง ฺฉุชุงุจุฎุงููโูุง ููุฑุฏ ูุงุฒุชุงู ุฑุง ูุงุฑุฏ ฺฉูุฏ.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99450f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amin/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from inspect import getsource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72faaed8",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "ูุนุฑู ูุฌููุนูโุฏุงุฏู\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "ุฏุฑ ุงู ุชูุฑู ุงุฒ ูุฌููุนูโโุฏุงุฏูโ ุณุงุฏู ุงูุง ูุดููุฑ ฺฏูโูุง ุฒูุจู (iris) ุงุณุชูุงุฏู ุฎูุงูู ฺฉุฑุฏ. ุงู ูุฌููุนูโุฏุงุฏู ุดุงูู ุณู ุฏุณุชู (ููุน ฺฏุงู) ุงุณุช ฺฉู ุงุฒ ูุฑ ุฏุณุชู 50 ููููู ุฏุงุฏู ูุฌูุฏ ุฏุงุฑุฏ. ูุฑ ุฏุงุฏู ุฏุงุฑุง ฺฉ ุจุฑฺุณุจ ู ฺูุงุฑ ูฺฺฏ ุงุณุช ฺฉู ุฏุฑ ุฌุฏูู ุฒุฑ ูุนุฑู ุดุฏูโุงูุฏ.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|ุณุชูู|ุชูุถุญุงุช|\n",
    "|:------:|:---:|\n",
    "|SepalLengthCm|ุทูู ฺฉุงุณุจุฑฺฏ (ุณุงูุชโูุชุฑ)|\n",
    "|SepalWidthCm|ุนุฑุถ ฺฉุงุณุจุฑฺฏ (ุณุงูุชโูุชุฑ)|\n",
    "|PetalLengthCm|ุทูู ฺฏูุจุฑฺฏ (ุณุงูุชโูุชุฑ)|\n",
    "|PetalWidthCm|ุนุฑุถ ฺฏูุจุฑฺฏ (ุณุงูุชโูุชุฑ)|\n",
    "|Species|ููุน ฺฏุงู (ูุชุบุฑ ูุฏู)|\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99bbe9b",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "ุฎูุงูุฏู ูุฌููุนู ุฏุงุฏู\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    ุฏุฑ ุงุจุชุฏุง ูุงุฒ ุงุณุช ูุงูโ ูุฌููุนูโุฏุงุฏู ุฑุง ุจุฎูุงูุฏ. ุจุฑุง ุงู ุชูุฑู ูุฌููุนูโ ุขุฒููู ุฏุฑ ูุธุฑ ฺฏุฑูุชู ูุดุฏู ู ูุฏู ุชููุง ูพุงุฏูโุณุงุฒ ู ุชุญูู ูุฏู ุงุณุช. ุจูุงุจุฑุงู ฺฉู ูุฌููุนูโุฏุงุฏู ุฑุง ูโุชูุงูุฏ ุงุฒ ูุงู <code>iris.csv</code> ููุฌูุฏ ุฏุฑ ูพูุดูโ ูุณุฆูู ุฎูุงูุฏู ู ุงุฒ ูููููโูุง ููุฌูุฏ ุฏุฑ ุขู ุจุฑุง ุขููุฒุด ูพุฑุณูพุชุฑูู ุงุณุชูุงุฏู ฺฉูุฏ. ุชูุฌู ุฏุงุดุชู ุจุงุดุฏ ฺฉู ูุงุฒ ุจู ุณุชูู <code>Id</code> ูุฏุงุฑุฏ ู ูโุชูุงูุฏ ุขู ุฑุง ุงุฒ ุฏุชุงูุฑู ุฎูุฏ ุญุฐู ฺฉูุฏ.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dcb9e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('../data/iris.csv') # To-Do\n",
    "train_data.drop(columns=['Id'], inplace=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1617a7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Species'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23daec54",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "ูพุดโูพุฑุฏุงุฒุด ู ูููุฏุณ ูฺฺฏ\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    ุงฺฏุฑ ุจู ููุงุฏุฑ ุณุชูู <code>Species</code> ูฺฏุงู ฺฉุฑุฏู ุจุงุดุฏุ ุฏุฑุงูุชูโุงุฏ ฺฉู ุงู ูุฌููุนูโุฏุงุฏู ุฏุงุฑุง ุณู ฺฉูุงุณ <code>Iris-setosa</code> ุ<code>Iris-versicolor</code> ู <code>Iris-virginica</code> ุงุณุช.\n",
    "    <br>\n",
    "    ุงุฒ ุขูุฌุง ฺฉู ฺฉ ูพุฑุณูพุชุฑูู ูุงุญุฏ ูุงุฏุฑ ุจู ุฏุณุชูโุจูุฏ ุฏูฺฉูุงุณู ูุณุช ุฏุฑ ุงู ุชูุฑู ูุตุฏ ุฏุงุฑู ุณู ูุฏู ูุฎุชูู ุฑุง ุขููุฒุด ุฏูู ฺฉู ูุฑฺฉุฏุงู ุงุฒ ุขูโูุง ุจู ฺฉ ุชุฑฺฉุจ ุฏูุชุง ุงุฒ ุณู ุฏุณุชู ููฺฉู ุชุตููโฺฏุฑ ูโฺฉูุฏ. ุนู ูุฑุงุฑ ุงุณุช ุชุง ุณู ูพุฑุณูพุชุฑูู ุฑุง ุจู ุดฺฉู ุฒุฑ ุขููุฒุด ุฏูู:\n",
    "</font>\n",
    "</p>\n",
    "<ul dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    <li>ุชุตููโฺฏุฑ ุจู ุฏู ุฏุณุชูโ <code>Iris-setosa</code> ู <code>Iris-versicolor</code></li>\n",
    "    <li>ุชุตููโฺฏุฑ ุจู ุฏู ุฏุณุชูโ <code>Iris-setosa</code> ู <code>Iris-virginica</code></li>\n",
    "    <li>ุชุตููโฺฏุฑ ุจู ุฏู ุฏุณุชูโ <code>Iris-versicolor</code> ู <code>Iris-virginica</code></li>\n",
    "</font>\n",
    "</ul>\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    ุงู ุงูุฑ ููฺูู ุจู ูุง ฺฉูฺฉ ูโฺฉูุฏ ุชุง ุจูโุตูุฑุช ุชุฌุฑุจ ฺฉุดู ฺฉูู ฺฉู ฺฉุฏุงู ุฏุณุชู ุงุฒ ุณุงุฑ ุฏุณุชูโูุง ุจูโุตูุฑุช ุฎุท ุชูฺฉฺฉโูพุฐุฑ ุงุณุช.\n",
    "</font>\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    ุจูุงุจุฑุงู ุงุฒ ุดูุง ุฎูุงุณุชู ูโุดูุฏ ฺฉู ุฏุชุงูุฑู ุงุตู ุฑุง ุจู ุณู ุฏุชุงูุฑู ฺฉูฺฺฉโุชุฑ (ุจุง ูุงูโูุง <code>df2</code> ุ<code>df1</code> ู <code>df3</code>) ุชูุณู ฺฉูุฏุ ุจู ุดฺฉู ฺฉู ุฏุฑ ูุฑ ุฏุชุงูุฑู ุชููุง ูููููโูุง ูุฑุจูุท ุจู ฺฉ ุงุฒ ุญุงูุชโูุง ูุณุช ุจุงูุง ูุฌูุฏ ุฏุงุดุชู ุจุงุดุฏ. ุจู ุนููุงู ูุซุงู ุฏุฑ ุฏุชุงูุฑู ูุฎุณุช ุนู <code>df1</code> ุชููุง ูููููโูุง ุญุงูุช ุงูู ุนู ุฏุณุชูโูุง <code>Iris-setosa</code> ู <code>Iris-versicolor</code> ูุฌูุฏ ุฏุงุดุชู ุจุงุดุฏ.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7c23000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows ร 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm          Species\n",
       "50             7.0           3.2            4.7           1.4  Iris-versicolor\n",
       "51             6.4           3.2            4.5           1.5  Iris-versicolor\n",
       "52             6.9           3.1            4.9           1.5  Iris-versicolor\n",
       "53             5.5           2.3            4.0           1.3  Iris-versicolor\n",
       "54             6.5           2.8            4.6           1.5  Iris-versicolor\n",
       "..             ...           ...            ...           ...              ...\n",
       "145            6.7           3.0            5.2           2.3   Iris-virginica\n",
       "146            6.3           2.5            5.0           1.9   Iris-virginica\n",
       "147            6.5           3.0            5.2           2.0   Iris-virginica\n",
       "148            6.2           3.4            5.4           2.3   Iris-virginica\n",
       "149            5.9           3.0            5.1           1.8   Iris-virginica\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = train_data[(train_data.Species == 'Iris-setosa') | (train_data.Species == 'Iris-versicolor')] # To-Do\n",
    "\n",
    "df2 = train_data[(train_data.Species == 'Iris-setosa') | (train_data.Species == 'Iris-virginica')]  # To-Do\n",
    "\n",
    "df3 = train_data[(train_data.Species == 'Iris-versicolor') | (train_data.Species == 'Iris-virginica')] # To-Do\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0927d1",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "ฺฉุฏ ุฒุฑ ุฏุชุงูุฑูโูุง ุดูุง ุฑุง ุฐุฎุฑู ูโฺฉูุฏ ุชุง ุฏุฑ ุงูุชูุง ูุชโุจูฺฉ ุจู ูุงู ุฌูุงุจ ุดูุง ุงุถุงูู ุดูุฏ. ุณู ุฏุชุงูุฑู ุจุงูุง ุงุฒ ูุธุฑ ุชุนุฏุงุฏ ูููููุ ุณุชููโูุง ู ููุงุฏุฑ ููุฌูุฏ ุฏุฑ ุณุชูู <code>Species</code> ุฏุงูุฑ ุฎูุงููุฏ ุดุฏ. ูุงุฒ ุจู ุชุบุฑ ฺฉุฏ ูุณุช ู ฺฉุงูุณุช ุชููุง ุณููู ุฑุง ุงุฌุฑุง ููุงุฏ.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "704751ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('df1.csv', index=False)\n",
    "df2.to_csv('df2.csv', index=False)\n",
    "df3.to_csv('df3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0923ecf5",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    ุงฺฉููู ุงฺฏุฑ ูุตุฏ ุฏุงุฑุฏ ูโุชูุงูุฏ ูพุดโูพุฑุฏุงุฒุดโูุง ุฏูุฎูุงู ุฎูุฏ ุฑุง ุจุฑ ุฑู ููุงุฏุฑ ูฺฺฏโูุง ุงูุฌุงู ุฏูุฏ. ููฺูู ุชูุฌู ุฏุงุดุชู ุจุงุดุฏ ููุงุฏุฑ ุณุชูู ุจุฑฺุณุจ ุฑุง ุจุงุฏ ุจู ุดฺฉู ุงุนุฏุงุฏ <code dir=ltr>+1</code> ู <code dir=ltr>-1</code> ฺฉุฏฺฏุฐุงุฑ ฺฉูุฏ. ุนูุงูู ุจุฑ ุงู ูุฑุงููุด ูฺฉูุฏ ฺฉู ุณุชููโูุง ูฺฺฏ ุฑุง ุงุฒ ุณุชูู ูุชุบุฑ ูุฏู (ุจุฑฺุณุจ) ุฌุฏุง ฺฉูุฏ.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f493320e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amin/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/generic.py:6619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "# To-Do\n",
    "df1['Species'].replace({'Iris-setosa': -1, 'Iris-versicolor': +1}, inplace=True)\n",
    "df2['Species'].replace({'Iris-setosa': -1, 'Iris-virginica': +1}, inplace=True)\n",
    "df3['Species'].replace({'Iris-versicolor': -1, 'Iris-virginica': +1}, inplace=True)\n",
    "\n",
    "df1_features = df1.drop(columns=['Species'])\n",
    "df1_target = df1['Species'] \n",
    "\n",
    "df2_features = df1.drop(columns=['Species'])\n",
    "df2_target = df1['Species'] \n",
    "\n",
    "df3_features = df1.drop(columns=['Species'])\n",
    "df3_target = df1['Species'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f2c94",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "ูุฏูโุณุงุฒ\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    ุงฺฉููู ฺฉู ุฏุงุฏูโูุง ุฑุง ูพุฑุฏุงุฒุด ู ุขูุงุฏู ฺฉุฑุฏุฏ ููุจุช ุจู ูุณูุช ุงุตู ุนู ูุฏู ูโุฑุณุฏ. ููุงูุทูุฑ ฺฉู ุฏุฑ ุงุจุชุฏุง ุฐฺฉุฑ ฺฉุฑุฏู ุฏุฑ ุงู ุชูุฑู ุฏฺฏุฑ ุฎุจุฑ ุงุฒ ฺฉุชุงุจุฎุงููโ ุขูุงุฏูโ <code>scikit-learn</code> ูุณุช. ุฏุฑ ุงูุฌุง ุงุฒ ุดูุง ุฎูุงุณุชู ุดุฏู ุชุง ฺฉ ูุฏู ุณุงุฏูโ ูพุฑุณูพุชุฑูู ุฑุง ุจู ุฏู ุญุงูุช (ูุงุนุฏูโ ูพุฑุณูพุชุฑูู ู ูุงุนุฏูโ ุฏูุชุง) ุงุฒ ุตูุฑ ูพุงุฏู ฺฉูุฏ. ุจุฑุง ุงู ฺฉุงุฑ ูุฏู ุจู ูุฏู ูุฑ ุฌุฒุก ุงู ูุฏู ุฑุง ุดุฑุญ ุฎูุงูู ุฏุงุฏ ุชุง ูุณุจุช ุจู ูพุงุฏูโโุณุงุฒ ุขู ุงูุฏุงู ฺฉูุฏ.\n",
    "    <br>\n",
    "    <b>ูฺฉุชู: </b>\n",
    "    ุฏุฑ ุงุนูุงู ุฑุงุถ ู ูุญุงุณุจุงุช ุฎูุฏ ุชููุง ุงุฒ ฺฉุชุงุจุฎุงููโ ูุงููพุง ุงุณุชูุงุฏู ฺฉูุฏ ู ูุณุชโูุง ุฎูุฏ ุฑุง ูุฒ ุจู ุดฺฉู ุขุฑุงูโ ูุงููพุง ุชุนุฑู ฺฉูุฏ.\n",
    "    <br>\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23321043",
   "metadata": {},
   "source": [
    "<h3 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "ูุงุนุฏูโ ูพุฑุณูพุชุฑูู\n",
    "</font>\n",
    "</h3>\n",
    "<center>\n",
    "    <img src=\"perceptron_rule.png\">\n",
    "<center>\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "    ุจู ููุธูุฑ ูพุงุฏูโุณุงุฒ ูุฏูุโ ฺฉูุงุณ ุจุง ูุงู <code>Perceptron</code> ุชุนุฑู ุฎูุงูู ฺฉุฑุฏ ฺฉู ุฏุฑ ููฺฏุงู ุณุงุฎุชู ุดุฏู (<code>__init__</code>) ฺฉ ูฺฺฏ ูุฑุชุจุท ุจุง ูุฒูโูุง ุฑุง ุจุง ูุงู <code>weights</code> ุจู ุงู ฺฉูุงุณ ุงุถุงูู ูโฺฉูุฏ. ุจูุงุจุฑุงู ุฏุฑ ููฺฏุงู ูพุงุฏูโุณุงุฒ ุชูุงุจุน ุฌูุช ุฏุณุชุฑุณ ุจู ูุฒูโูุง ูพุฑุณูพุชุฑูู ูโุชูุงูุฏ ุงุฒ <code>self.weights</code> ุงุณุชูุงุฏู ฺฉูุฏ.\n",
    "    <br>\n",
    "    ุงฺฉููู ูุฑฺฉุฏุงู ุงุฒ ุชูุงุจุน ููุฑุฏ ูุงุฒ ุงู ฺฉูุงุณ ุฑุง ุดุฑุญ ุฎูุงูู ุฏุงุฏ ุชุง ุดูุง ุจู ูพุงุฏูโุณุงุฒ ุขูโูุง ุจูพุฑุฏุงุฒุฏ:\n",
    "    <br>\n",
    "    <ul dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "        <li>\n",
    "        ุชุงุจุน <code>weighting</code> ููุงุฏุฑ ูฺฺฏโูุง ฺฉ ููููู ุฑุง ฺฏุฑูุชู ู ุขู ุฑุง ุฏุฑ ุจุฑุฏุงุฑ ูุฒู ุถุฑุจ ููุทูโุง ูโฺฉูุฏ. ุณูพุณ ูุฑูุฏ ูุฒูโุฏุงุฑ ุดุฏู ุจู ุนููุงู ุฎุฑูุฌ ุจุฑฺฏุฑุฏุงูุฏู ูโุดูุฏ.\n",
    "        </li>\n",
    "        <li>\n",
    "        ุฏุฑ ุชุงุจุน ุจู ูุงู <code>activation</code> ุชุงุจุน ูุนุงูโุณุงุฒ ุฑุง ฺฉู ุฏุฑ ุงูุฌุง ุชุงุจุน ุนูุงูุช ุงุณุช ูพุงุฏู ุฎูุงูู ฺฉุฑุฏ. ุงู ุชุงุจุนุ ูุฑูุฏ ูุฒูโุฏุงุฑ ุฑุง ฺฏุฑูุชู ู ุฏุฑ ุตูุฑุชฺฉู ุญุงุตู ุจุดุชุฑ ุง ูุณุงู ุตูุฑ ุจูุฏ ุฎุฑูุฌ <code>1</code> ู ุฏุฑ ุบุฑ ุงูโุตูุฑุช ุฎุฑูุฌ <code dir=ltr>-1</code> ุชููุฏ ูโฺฉูุฏ.\n",
    "        </li>\n",
    "        <li>\n",
    "        ุชุงุจุน <code>predict</code> ุขุฑุงูโุง ุงุฒ ูููููโูุง ุฑุง ฺฏุฑูุชู ู ุขุฑุงูโุง ุดุงูู ุจุฑฺุณุจ ูพุดโุจูโุดุฏู ุจุฑุง ูุฑฺฉุฏุงู ุงุฒ ูููููโูุง ุฑุง ุจุฑ ูโฺฏุฑุฏุงูุฏ. ุฏุฑ ุงู ุชุงุจุน ุจุงุฏ ุจู ุงุฒุง ูุฑ ููููู ุงุจุชุฏุง ุขู ุฑุง ุจู ฺฉูฺฉ ุชุงุจุน <code>weighting</code> ูุฒู ุฏุงุฑ ฺฉูุฏ ู ุญุงุตู ุฑุง ุจู ุชุงุจุน <code>activation</code> ุจุฏูุฏ ุชุง ุจุฑฺุณุจ <code dir=ltr>+1</code> ุง <code dir=ltr>-1</code> ุฑุง ุจุฑุง ููููู ุชููุฏ ฺฉูุฏ.\n",
    "        </li>\n",
    "        <li>\n",
    "        ุงูฺฏูุฑุชู ุงุตู ูพุฑุณูพุชุฑูู ุฏุฑ ูุงูุน ุฏุฑ ุชุงุจุน <code>fit</code> ูพุงุฏู ูโุดูุฏ. ุงู ุชุงุจุน ูุฑูุฏโูุง ู ูุงูพุฑูพุงุฑุงูุชุฑูุง ุฒุฑ ุฑุง ฺฏุฑูุชู ู ุณูพุณ ุทุจู ูุฑุงุญู ฺฉู ุดุฑุญ ุฎูุงูู ุฏุงุฏ ุดุฑูุน ุจู ุขููุฒุด [ูุฒูโูุง] ูพุฑุณูพุชุฑูู ูโฺฉูุฏ.\n",
    "        </li>\n",
    "    </ul>\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|ูุฑูุฏ|ุชูุถุญุงุช|\n",
    "|:------:|:---:|\n",
    "|inputs|ูฺฺฏโูุง ูุฑูุฏ ูููููโูุง ุขููุฒุด|\n",
    "|outputs|ูุชุบุฑ ูุฏู (ุจุฑฺุณุจ) ูููููโโูุง ุขููุฒุด|\n",
    "|learning_rate|ูุฑุฎ ุงุฏฺฏุฑ (ฮท)|\n",
    "|epochs|ุชุนุฏุงุฏ ุฏูุนุงุช ุขููุฒุด ุจุฑ ุฑู ุชูุงู ูููููโูุง|\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium; padding-right:40px;\">\n",
    "<font face=\"vazir\">\n",
    "ุฏุฑ ุฏุฑุณูุงููโ ูพุฑุณูพุชุฑูู ุงุดุงุฑู ฺฉุฑุฏู ฺฉู ุนุจุงุฑุช ุจุงุงุณ ุฑุง ูโุชูุงู ุจู ฺฉูฺฉ ุงุถุงูู ฺฉุฑุฏู ฺฉ ูุฑูุฏ ุซุงุจุช <code>1</code> ุจู ูฺฺฏโูุง ูุฑูุฏ ุชุนุจู ฺฉุฑุฏ. ุจูุงุจุฑุงู ุฏุฑ ุชุงุจุน <code>fit</code> ุงุจุชุฏุง ุจู ุงูู ูฺฺฏโูุง ูุฑฺฉุฏุงู ุงุฒ ูููููโูุง ุนุฏุฏ <code>1</code> ุฑุง ุงุถุงูู ฺฉูุฏ (ุจู ุนููุงู ูุซุงู ุจุฑุง ูููููโ <code>inputs[i]</code>ุ ุจุงุฏ <code>inputs[i][0]</code> ุจุฑุงุจุฑ <code>1</code> ุจุงุดุฏ). ุจุง ุงู ฺฉุงุฑ ฺฉ ูุงุญุฏ ุจู ุทูู ุจุฑุฏุงุฑ ูฺฺฏ ูููููโูุง ุงุถุงูู ุฎูุงูุฏ ุดุฏ. (ูุฑุงููุด ูฺฉูุฏ ฺฉู ุงู ฺฉุงุฑ ุฑุง ุฏุฑ ููฺฏุงู ูพุดโุจู ุนู ุชุงุจุน predict ูุฒ ุจุงุฏ ุงูุฌุงู ุฏูุฏ.)\n",
    "<br>\n",
    "ูพุณ ุงุฒ ุขู ูุงุฒ ุงุณุช ุชุง ุจุฑุฏุงุฑ ูุฒู ุนู <code>self.weights</code> ุฑุง ุณุงุฎุชู ู ููุฏุงุฑุฏู ฺฉูุฏ. ุจุฑุง ููุฏุงุฑุฏู ุงููู ูโุชูุงูุฏ ุงุฒ ุงุนุฏุงุฏ ุชุตุงุฏู ุจู <code dir=ltr>0</code> ุชุง <code dir=ltr>1</code> ุงุณุชูุงุฏู ฺฉูุฏ.\n",
    "<br>\n",
    "ุณูพุณ ุฏุฑ ฺฉ ุญููู ุจู ุงุฒุง ูุฑ ุฏูุฑ (ุจู ุชุนุฏุงุฏ <code>epochs</code>) ุจุงุฏ ฺฉโุจุงุฑ ฺฉู ูุฌููุนูโ ุขููุฒุด ุฑุง ุจุฑุฑุณ ฺฉูุฏ. ุจูุงุจุฑุงู ุฏุฑ ุฏุงุฎู ุงู ุญูููุ ฺฉ ุญูููโ ุฏฺฏุฑ ุฎูุงูุฏ ุฏุงุดุช ฺฉู ูุฑุจุงุฑ ฺฉ ุงุฒ ูููููโูุง ุฑุง ุจุฑุฑุณ ูโฺฉูุฏ (ุจู ุฏูู ุงุณุชูุงุฏู ุงุฒ ุฑูุด ฺฉุงูุด ฺฏุฑุงุฏุงู ุชุตุงุฏู ุฏุฑ ูุฑ ุชฺฉุฑุงุฑ ุชููุง ฺฉ ููููู ุจุฑุฑุณ ู ูุฒูโูุง ุขูพุฏุช ูโุดููุฏ).\n",
    "<br>\n",
    "ุจู ุงุฒุง ูุฑ ูููููุ ุงุจุชุฏุง ุจู ฺฉูฺฉ ุชุงุจุน <code>weighting</code> ุจุฑุฏุงุฑ ูฺฺฏ ุขู ุฑุง ุฏุฑ ุจุฑุฏุงุฑ ูุฒู ุถุฑุจ ููุทูโุง ูโฺฉูู ุชุง ูุฑูุฏ ูุฒูโุฏุงุฑ ุจู ุฏุณุช ุขุฏ. ุณูพุณ ุญุงุตู ุจูโุฏุณุชโุขูุฏู ุฑุง ุจู ุชุงุจุน ูุนุงูโุณุงุฒ ูโุฏูู ุชุง ููุฏุงุฑ ุฎุฑูุฌ ูุฏู ุฑุง ุชููุฏ ฺฉูุฏ. ุญุงู ุจุง ุชูุฑู ูพุดโุจู ูุฏู ุงุฒ ููุฏุงุฑ (ุจุฑฺุณุจ) ูุงูุน ูโุชูุงูู ุงุฎุชูุงูโุดุงู ุฑุง ุจู ุฏุณุช ุขูุฑู. ุณูพุณ ุทุจู ูุฑูููโูุง ูุนุฑูโุดุฏู ุฏุฑ ุฏุฑุณูุงููุ ุจุง ุถุฑุจ ุงู ุงุฎุชูุงู ุฏุฑ ูุฑุฎ ุงุฏฺฏุฑ ู ูฺฺฏโูุง ูุฑูุฏ ู ุณูพุณ ุฌูุน ุขู ุจุง ููุงุฏุฑ ูุจู ุจุฑุฏุงุฑ ูุฒู ูโุชูุงูู ุจู ุขูพุฏุช ุจุฑุฏุงุฑ ูุฒู ุจูพุฑุฏุงุฒู.\n",
    "<br>\n",
    "ูพุดููุงุฏ ูโุดูุฏ ุฏุฑ ุขุฎุฑ ูุฑ ุฏูุฑ ูุณุจุช ุจู ฺุงูพ ุฏูุช ูุฏู ฺฉููู ุจุฑ ุฑู ูุฌููุนูโ ุขููุฒุด ูุฒ ุงูุฏุงู ฺฉูุฏ. ุจุฑุง ุงู ฺฉุงุฑ ฺฉุงูุณุช ูููููโูุง ุฑุง ุจู ุชุงุจุน <code>predict</code> ุจุฏูุฏ ุชุง ูพุดโุจู ูุฏู ุชููุฏ ุดูุฏ ู ุณูพุณ ุจู ฺฉูฺฉ ุชุงุจุน ุขูุงุฏูโ <code>accuracy_score</code> ุฏูุช ุขู ุฑุง ุจู ุฏุณุช ุขูุฑุฏ.\n",
    "<br>\n",
    "<b>ูฺฉุชู: </b>\n",
    "ุฏุฑ ูฺโฺฉุฏุงู ุงุฒ ุชูุงุจุน ุฎูุฏ ุจู ุบุฑ ุงุฒ ุชุงุจุน <code>fit</code> ฺุฒ ุฑุง ฺุงูพ (<code>print</code>) ูฺฉูุฏุ ุฏุฑ ุบุฑ ุงูโุตูุฑุช ุณุณุชู ุฏุงูุฑ ูุงุฏุฑ ุจู ุงูุชุงุฒุฏู ุจู ุชูุงุจุน ุดูุง ูุฎูุงูุฏ ุจูุฏ.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "231cd2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "\n",
    "    def weighting(self, input):\n",
    "        weighted_sum = np.dot(input, self.weights)\n",
    "        return weighted_sum # To-Do\n",
    "\n",
    "    def activation(self, weighted_input):\n",
    "        if weighted_input >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1 # To-Do\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        # adding a 1 to the first position of each input (adding the bias term)\n",
    "        new_inputs = np.insert(inputs, 0, 1, axis=1)# To-Do\n",
    "        # a list of final prediction for each test sample\n",
    "        predictions = []\n",
    "        for input in new_inputs:\n",
    "            weighted_input = self.weighting(input)# To-Do\n",
    "            prediction = self.activation(weighted_input)# To-Do\n",
    "            predictions.append(prediction)\n",
    "        # converting the list to a numpy array\n",
    "        predictions = np.array(predictions)\n",
    "        return predictions\n",
    "\n",
    "    def fit(self, inputs, outputs, learning_rate=0.1, epochs=64):\n",
    "        # adding a 1 to the first position of each input (adding the bias term)\n",
    "        new_inputs = np.insert(inputs, 0, 1, axis=1) # To-Do\n",
    "        # initializing the weights\n",
    "        self.weights = np.random.rand(new_inputs.shape[1])\n",
    "        # training loop\n",
    "        for epoch in range(epochs):\n",
    "            for sample, target in zip(new_inputs, outputs):\n",
    "                weighted_input = self.weighting(sample)# To-Do (using self.weighting on sample)\n",
    "                pred = self.activation(weighted_input)\n",
    "                diff =  target - pred# To-Do (based on target and self.activation)\n",
    "                self.weights += diff * learning_rate * sample # To-Do (based on self.weights, learning_rate, diff and sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a46903",
   "metadata": {},
   "source": [
    "<h4 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "ุขููุฒุด ูุฏู\n",
    "</font>\n",
    "</h4>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "    ูพุณ ุงุฒ ุทุฑุงุญ ุณุงุฎุชุงุฑ ูพุฑุณูพุชุฑูู ูโุชูุงูุฏ ุจู ฺฉูฺฉ <code dir=ltr>Perceptron()</code> ุงุจุชุฏุง ฺฉ ููููู ุงุฒ ุงู ฺฉูุงุณ ุจุณุงุฒุฏ ู ุณูพุณ ุชุงุจุน <code>fit</code> ุฑุง ุจุง ุขุฑฺฏููุงูโูุง ููุงุณุจ ุตุฏุง ุจุฒูุฏ ุชุง ุขููุฒุด ูุฏู ุขุบุงุฒ ุดูุฏ. ุงู ฺฉุงุฑ ุฑุง ุจุฑุง ูุฑ ุณู ุญุงูุช ูุฑูุฏ ุงูุฌุงู ุฏูุฏ. ูพุดููุงุฏ ูโุดูุฏ ููุงุฏุฑ ูุฎุชูู ูุฑุฎ ุงุฏฺฏุฑ ูุงููุฏ 0.1ุ 0.01ุ 0.001 ู... ุฑุง ุขุฒูุงุด ู ููุงุณู ฺฉูุฏ.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4f7297d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (100, 5), indices imply (100, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m perceptron \u001b[39m=\u001b[39m Perceptron()\n\u001b[0;32m----> 2\u001b[0m perceptron\u001b[39m.\u001b[39;49mfit(df1_features, df1_target) \u001b[39m# To-Do\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[36], line 31\u001b[0m, in \u001b[0;36mPerceptron.fit\u001b[0;34m(self, inputs, outputs, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, inputs, outputs, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m):\n\u001b[1;32m     30\u001b[0m     \u001b[39m# adding a 1 to the first position of each input (adding the bias term)\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     new_inputs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49minsert(inputs, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39m# To-Do\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[39m# initializing the weights\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(new_inputs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36minsert\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/numpy/lib/function_base.py:5357\u001b[0m, in \u001b[0;36minsert\u001b[0;34m(arr, obj, values, axis)\u001b[0m\n\u001b[1;32m   5355\u001b[0m     new[\u001b[39mtuple\u001b[39m(slobj)] \u001b[39m=\u001b[39m arr[\u001b[39mtuple\u001b[39m(slobj2)]\n\u001b[1;32m   5356\u001b[0m     \u001b[39mif\u001b[39;00m wrap:\n\u001b[0;32m-> 5357\u001b[0m         \u001b[39mreturn\u001b[39;00m wrap(new)\n\u001b[1;32m   5358\u001b[0m     \u001b[39mreturn\u001b[39;00m new\n\u001b[1;32m   5359\u001b[0m \u001b[39melif\u001b[39;00m indices\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m   5360\u001b[0m     \u001b[39m# Can safely cast the empty list to intp\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/generic.py:2025\u001b[0m, in \u001b[0;36mNDFrame.__array_wrap__\u001b[0;34m(self, result, context)\u001b[0m\n\u001b[1;32m   2022\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_axes_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_AXIS_ORDERS, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2023\u001b[0m \u001b[39m# error: Argument 1 to \"NDFrame\" has incompatible type \"ndarray\";\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m \u001b[39m# expected \"BlockManager\"\u001b[39;00m\n\u001b[0;32m-> 2025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_constructor(res, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49md)\u001b[39m.\u001b[39m__finalize__(  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m     \u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m__array_wrap__\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2027\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/frame.py:672\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    662\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    663\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    664\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    669\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    670\u001b[0m         )\n\u001b[1;32m    671\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 672\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    673\u001b[0m             data,\n\u001b[1;32m    674\u001b[0m             index,\n\u001b[1;32m    675\u001b[0m             columns,\n\u001b[1;32m    676\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    677\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    678\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    679\u001b[0m         )\n\u001b[1;32m    681\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/internals/construction.py:324\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    320\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    321\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    322\u001b[0m )\n\u001b[0;32m--> 324\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    326\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    328\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/internals/construction.py:393\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    391\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    392\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> 393\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (100, 5), indices imply (100, 4)"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(df1_features, df1_target) # To-Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e48be138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-500.03652508,  277.07236665, -146.17454133,  133.4052457 ,\n",
       "        100.4345656 ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(df2_features, df2_target, 0.1, 10) # To-Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e1c9f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-499.89779564, -341.50292081,  426.70810698,  133.559198  ,\n",
       "        100.0580591 ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(df3_features, df3_target, 0.1, 10) # To-Do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d87e34",
   "metadata": {},
   "source": [
    "<h4 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "๐ค\n",
    "ูพุฑุณุด\n",
    "</font>\n",
    "</h4>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "    ุงุฒ ูุงู ุณู ุญุงูุช ูุฎุชูู ฺฉู ุจุฑุง ฺฉูุงุณโูุง ูุฌููุนูโุฏุงุฏู ุฏุฑ ูุธุฑ ฺฏุฑูุชูุ ฺฉ ุง ฺูุฏ ุญุงูุช ุจูโุตูุฑุช ุฎุท ุชูฺฉฺฉโูพุฐุฑ ูุณุชูุฏ. ุชูฺฉฺฉโูพุฐุฑ ุฎุท ุจูุฏู ุขูโูุง ุฑุง ูโุชูุงู ุทุจู ุฏูุช ุจูโุฏุณุชโุขูุฏู ุชูุณุท ูุฏู ูุชุฌูโฺฏุฑ ฺฉุฑุฏ. ุทุจู ูุชุงุฌ ุจูโุฏุณุชโุขูุฏู ุฏุฑ ุงุฌุฑุง ุฎูุฏ ูฺฉุฑ ูโฺฉูุฏ ฺฉุฏุงู ุญุงูุช ุง ุญุงูุชโูุง ุจูโุตูุฑุช ุฎุท ุชูฺฉฺฉโูพุฐุฑ ูุณุชูุฏุ ูพุงุณุฎ ุฑุง ุฏุฑ ูุชุบุฑ <code>linearly_separable</code> ุจู ุดฺฉู ฺฉ ูุณุช ูุงุฑุฏ ฺฉูุฏ. ุจู ุนููุงู ูุซุงู ุงฺฏุฑ ูพุงุณุฎ ุดูุง ุญุงูุช ุงูู ุนู ฺฉูุงุณโูุง <code>Iris-setosa</code> ู <code>Iris-versicolor</code> ุงุณุช ุขูฺฏุงู <code>linearly_separable</code> ุฑุง ุจูโุตูุฑุช <code>[1]</code> ู ุงฺฏุฑ ูพุงุณุฎ ุดูุง ูุซูุงู ุญุงูุช ุฏูู ู ุณูู ุงุณุช ุขู ุฑุง ุจู ุดฺฉู <code dir=ltr>[2, 3]</code> ููุฏุงุฑุฏู ฺฉูุฏ.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9c9053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linearly_separable = [1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b86c670",
   "metadata": {},
   "source": [
    "<h3 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "ูุงุนุฏูโ ุฏูุชุง\n",
    "</font>\n",
    "</h3>\n",
    "<center>\n",
    "<img src=\"delta_rule.png\">\n",
    "</center>\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "    ุฏุฑ ุงู ุญุงูุช ูโุฎูุงูู ฺฉูุงุณ ุจุง ูุงู <code>Adaline</code> ุจุณุงุฒู ู  ูุฏู ุฑุง ุจุง ูุงุนุฏูโ ุฏูุชุง ุขููุฒุด ุฏูู. ุฏุฑ ุงูุฌุง ุงุฒ ุฑูุด ูุฒูู ฺฏุฑุงุฏุงู ุงุณุชูุงุฏู ุฎูุงูู ฺฉุฑุฏุ ุนู ุชูุงู ูููููโูุง ุขููุฒุด ุจูโุตูุฑุช ููุฒูุงู ุจุฑ ุฑู ุขูพุฏุช ูุฒู ุชุงุซุฑ ูโฺฏุฐุงุฑูุฏ (ุจุฑุฎูุงู ุฑูุด ูุฒูู ฺฏุฑุงุฏุงู ุชุตุงุฏู ฺฉู ูุฑุจุงุฑ ฺฉ ููููู ุฏุฏู ูโุดุฏ). ฺฉุฏ ุงู ูุฏู ุจุณุงุฑ ุดุจู ุจู ุญุงูุช ูุจู ุฎูุงูุฏ ุจูุฏ ู ุชููุง ูุงุฒ ุงุณุช ฺูุฏ ููุฑุฏ ุฌุฒุฆ ุฒุฑ ุฑุง ุงุนูุงู ฺฉูุฏ:\n",
    "    <br>\n",
    "    <ul dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "        <li>\n",
    "        ุงุฒ ุขูุฌุง ฺฉู ุฏุฑ ุงู ุญุงูุช ุงุฒ ุชุงุจุน ูุนุงูโุณุงุฒ ุฎุท ุงุณุชูุงุฏู ูโุดูุฏ ุชุงุจุน <code>activation</code> ุชููุง ููุงู ูุฑูุฏ ูุฒูโุฏุงุฑ ุฎูุฏ ุฑุง ุจุฏูู ูฺโฺฏููู ุชุบุฑ ุฎุฑูุฌ ูโุฏูุฏ.\n",
    "        </li>\n",
    "        <li>\n",
    "        ุฏุฑ ุชุงุจุน <code>prediction</code> ูพุณ ุงุฒ ูุฒูโุฏุงุฑ ฺฉุฑุฏู ู ุนุจูุฑ ุงุฒ ุชุงุจุน ูุนุงูโุณุงุฒุ ุจุงุฏ ุจุฑุฑุณ ฺฉูุฏ ฺฉู ุงฺฏุฑ ุญุงุตู ุจุฒุฑฺฏุชุฑ ุง ูุณุงู ุตูุฑ ุจูุฏุ ููุฏุงุฑ ูพุดโุจู <code dir=ltr>+1</code> ู ุฏุฑ ุบุฑ ุงูโุตูุฑุช <code dir=ltr>-1</code> ุดูุฏ.\n",
    "        </li>\n",
    "        <li>\n",
    "        ูพุดููุงุฏ ูโุดูุฏ ุจู ุฌุง ุงูฺฉู ฺฉ ุญููู ุจููุณุฏ ฺฉู ุฎุทุง ูุฑ ููููู ุฑุง ูุญุงุณุจู ฺฉูุฏ ู ุฏุฑ ุขุฎุฑ ุงุฒ ูุฌููุน ุขู ุฌูุช ุขูพุฏุช ูุฒู ุงุณุชูุงุฏู ฺฉูุฏุ ููู ฺฉุงุฑ ุฑุง ุจูโุตูุฑุช ุจุฑุฏุงุฑ ุงูุฌุงู ุฏูุฏ (ุจุง ุถุฑุจ ููุทูโุง ุชุฑุงููุงุฏูโ ูุงุชุฑุณ ูุฑูุฏ ุฏุฑ ุจุฑุฏุงุฑ ูุฒู).\n",
    "        </li>\n",
    "    </ul>\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7961eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "\n",
    "    def weighting(self, input):\n",
    "        weighted_sum = np.dot(input, self.weights)\n",
    "        return weighted_sum # To-Do\n",
    "\n",
    "    def activation(self, weighted_input):\n",
    "        return weighted_input # To-Do\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        # adding a 1 to the first position of each input (adding the bias term)\n",
    "        new_inputs = np.insert(inputs, 0, 1, axis=1)# To-Do\n",
    "        # a list of final prediction for each test sample\n",
    "        predictions = []\n",
    "        for input in new_inputs:\n",
    "            weighted_input = self.weighting(input)# To-Do\n",
    "            prediction = self.activation(weighted_input)# To-Do\n",
    "            if prediction >= 0:\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(-1)\n",
    "        # converting the list to a numpy array\n",
    "        predictions = np.array(predictions)\n",
    "        return predictions\n",
    "\n",
    "    def fit(self, inputs, outputs, learning_rate=0.1, epochs=64):\n",
    "        # adding a 1 to the first position of each input (adding the bias term)\n",
    "        new_inputs = np.insert(inputs, 0, 1, axis=1) # To-Do\n",
    "        # initializing the weights\n",
    "        self.weights = np.random.rand(new_inputs.shape[1])\n",
    "        # training loop\n",
    "        for epoch in range(epochs):\n",
    "            for sample, target in zip(new_inputs, outputs):\n",
    "                weighted_input = self.weighting(sample)# To-Do (using self.weighting on sample)\n",
    "                pred = self.activation(weighted_input)\n",
    "                diff =  target - pred# To-Do (based on target and self.activation)\n",
    "                self.weights += diff * learning_rate * sample # To-Do (based on self.weights, learning_rate, diff and sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25901f4f",
   "metadata": {},
   "source": [
    "<h4 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "ุขููุฒุด ูุฏู\n",
    "</font>\n",
    "</h4>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "    ูพุณ ุงุฒ ุทุฑุงุญ ุณุงุฎุชุงุฑ ูพุฑุณูพุชุฑูู ูโุชูุงูุฏ ุจู ฺฉูฺฉ <code dir=ltr>Adaline()</code> ุงุจุชุฏุง ฺฉ ููููู ุงุฒ ุงู ฺฉูุงุณ ุจุณุงุฒุฏ ู ุณูพุณ ุชุงุจุน <code>fit</code> ุฑุง ุจุง ุขุฑฺฏููุงูโูุง ููุงุณุจ ุตุฏุง ุจุฒูุฏ ุชุง ุขููุฒุด ูุฏู ุขุบุงุฒ ุดูุฏ. ุงู ฺฉุงุฑ ุฑุง ุจุฑุง ูุฑ ุณู ุญุงูุช ูุฑูุฏ ุงูุฌุงู ุฏูุฏ. ูพุดููุงุฏ ูโุดูุฏ ููุงุฏุฑ ูุฎุชูู ูุฑุฎ ุงุฏฺฏุฑ ูุงููุฏ 0.1ุ 0.01ุ 0.001 ู... ุฑุง ุขุฒูุงุด ู ููุงุณู ฺฉูุฏ.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "008fcefd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (100, 5), indices imply (100, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m adaline \u001b[39m=\u001b[39m Adaline()\n\u001b[0;32m----> 2\u001b[0m adaline\u001b[39m.\u001b[39;49mfit(df1_features, df1_target) \u001b[39m# To-Do\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 31\u001b[0m, in \u001b[0;36mAdaline.fit\u001b[0;34m(self, inputs, outputs, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, inputs, outputs, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m):\n\u001b[1;32m     30\u001b[0m     \u001b[39m# adding a 1 to the first position of each input (adding the bias term)\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     new_inputs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49minsert(inputs, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39m# To-Do\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[39m# initializing the weights\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(new_inputs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36minsert\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/numpy/lib/function_base.py:5357\u001b[0m, in \u001b[0;36minsert\u001b[0;34m(arr, obj, values, axis)\u001b[0m\n\u001b[1;32m   5355\u001b[0m     new[\u001b[39mtuple\u001b[39m(slobj)] \u001b[39m=\u001b[39m arr[\u001b[39mtuple\u001b[39m(slobj2)]\n\u001b[1;32m   5356\u001b[0m     \u001b[39mif\u001b[39;00m wrap:\n\u001b[0;32m-> 5357\u001b[0m         \u001b[39mreturn\u001b[39;00m wrap(new)\n\u001b[1;32m   5358\u001b[0m     \u001b[39mreturn\u001b[39;00m new\n\u001b[1;32m   5359\u001b[0m \u001b[39melif\u001b[39;00m indices\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m   5360\u001b[0m     \u001b[39m# Can safely cast the empty list to intp\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/generic.py:2025\u001b[0m, in \u001b[0;36mNDFrame.__array_wrap__\u001b[0;34m(self, result, context)\u001b[0m\n\u001b[1;32m   2022\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_axes_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_AXIS_ORDERS, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2023\u001b[0m \u001b[39m# error: Argument 1 to \"NDFrame\" has incompatible type \"ndarray\";\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m \u001b[39m# expected \"BlockManager\"\u001b[39;00m\n\u001b[0;32m-> 2025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_constructor(res, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49md)\u001b[39m.\u001b[39m__finalize__(  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m     \u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m__array_wrap__\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2027\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/frame.py:672\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    662\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    663\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    664\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    669\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    670\u001b[0m         )\n\u001b[1;32m    671\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 672\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    673\u001b[0m             data,\n\u001b[1;32m    674\u001b[0m             index,\n\u001b[1;32m    675\u001b[0m             columns,\n\u001b[1;32m    676\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    677\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    678\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    679\u001b[0m         )\n\u001b[1;32m    681\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/internals/construction.py:324\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    320\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    321\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    322\u001b[0m )\n\u001b[0;32m--> 324\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    326\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    328\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/internals/construction.py:393\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    391\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    392\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> 393\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (100, 5), indices imply (100, 4)"
     ]
    }
   ],
   "source": [
    "adaline = Adaline()\n",
    "adaline.fit(df1_features, df1_target) # To-Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75920d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5009/1789267452.py:32: RuntimeWarning: invalid value encountered in add\n",
      "  self.weights += dif *(learning_rate * inputs[j, :])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaline = Adaline()\n",
    "adaline.fit(df2_features, df2_target) # To-Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "598042ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5009/1789267452.py:32: RuntimeWarning: invalid value encountered in add\n",
      "  self.weights += dif *(learning_rate * inputs[j, :])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaline = Adaline()\n",
    "adaline.fit(df3_features, df3_target) # To-Do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08def517",
   "metadata": {},
   "source": [
    "<h4 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "๐ญ\n",
    "ุชูฺฉุฑ\n",
    "</font>\n",
    "</h4>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "    ููุงุณูโ ุนููฺฉุฑุฏ ุฏู ูุฏู <code>Perceptron</code> ู <code>Adaline</code> ุฏุฑ ุญุงูุช ฺฉู ูุฌููุนูโุฏุงุฏู ุจู ุดฺฉู ุฎุท ุชูฺฉฺฉโูพุฐุฑ ูุจุงุดุฏ ูโุชูุงูุฏ ุจู ุดฺฉู ุนูู ุชูุงูุช ูุงู ุงู ุฏู ูุฏู ุฑุง ุจุฑุงโุชุงู ุดูุงู ุณุงุฒุฏ.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09c5f3",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>ุฏุงูุฑ</b>\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "ุฏุฑ ุงู ุชูุฑู ูุฑฺฉุฏุงู ุงุฒ ุชูุงุจุน ฺฉู ูพุงุฏู ฺฉุฑุฏูโุงุฏ ุจูโุตูุฑุช ุฌุฏุงฺฏุงูู ููุฑุฏ ุฏุงูุฑ ูุฑุงุฑ ุฎูุงูุฏ ฺฏุฑูุช ุชุง ุงุฒ ุนููฺฉุฑุฏ ูุฑฺฉุฏุงู ุจู ุดฺฉู ุฌุฏุงฺฏุงูู ูุทูุฆู ุดูุฏ. ุงูุจุชู ุชุงุจุน <code>fit</code> ูุฑ ฺฉูุงุณ ุจู ููุฒููโ ุนููฺฉุฑุฏ ฺฉู ูุฏู ุงุณุช ู ุฌูุช ุงุฑุฒุงุจุ ูุฏู ุดูุง ุจุฑ ุฑู ฺฉ ุญุงูุช ุชูฺฉฺฉโูพุฐุฑ ุฎุท ุงุฒ ูุฌููุนูโุฏุงุฏู iris ุขููุฒุด ุฎูุงูุฏ ุฏุฏ ู ุงูุชุธุงุฑ ูโุฑูุฏ ฺฉู ุจุชูุงูุฏ ุฏูุช ุชูุฑุจ ฑฐฐ ุฏุฑุตุฏ ุฑุง ุจุฑ ุฑู ูุฌููุนูโ ุขููุฒุด ุจู ุฏุณุช ุขูุฑุฏ. ุนูุงูู ุจุฑ ุงู ุฏุชุงูุฑูโูุง ุงููู ู ูพุงุณุฎ ุดูุง ุจู ูพุฑุณุด ูุทุฑุญโุดุฏู ุฏุฑุจุงุฑูโ ุชูฺฉฺฉโูพุฐุฑ ุฎุท ูุฒ ุงูุชุงุฒุฏู ุฎูุงูุฏ ุดุฏ.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a77e7cd",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>ุณููู ุฌูุงุจโุณุงุฒ</b>\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    ุณูููโูุง ุฒุฑ ุฑุง ุจู ููุธูุฑ ุณุงุฎุช ูุงูโูุง ฺฉูุงุณโูุง ูพุงุฏูโุณุงุฒ ุดุฏู ู ูพุงุณุฎ ุฎูุฏ ุจู ูพุฑุณุด ูุทุฑุญ ุดุฏู ุงุฌุฑุง ููุงุฏ.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e847dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"linearly_separable.json\", \"w\") as f:\n",
    "    json.dump(linearly_separable, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e18c2ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_perceptron = Perceptron()\n",
    "with open(\"Perceptron.py\", \"w\") as f:\n",
    "    f.write('import numpy as np\\n')\n",
    "    f.write('from sklearn.metrics import accuracy_score\\n')\n",
    "    f.write('class Perceptron:\\n')\n",
    "    f.write(getsource(inspect_perceptron.__init__)+'\\n')\n",
    "    f.write(getsource(inspect_perceptron.weighting)+'\\n')\n",
    "    f.write(getsource(inspect_perceptron.activation)+'\\n')\n",
    "    f.write(getsource(inspect_perceptron.predict)+'\\n')\n",
    "    f.write(getsource(inspect_perceptron.fit)+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "233b9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_adaline = Adaline()\n",
    "with open(\"Adaline.py\", \"w\") as f:\n",
    "    f.write('import numpy as np\\n')\n",
    "    f.write('from sklearn.metrics import accuracy_score\\n')\n",
    "    f.write('class Adaline:\\n')\n",
    "    f.write(getsource(inspect_adaline.__init__)+'\\n')\n",
    "    f.write(getsource(inspect_adaline.weighting)+'\\n')\n",
    "    f.write(getsource(inspect_adaline.activation)+'\\n')\n",
    "    f.write(getsource(inspect_adaline.predict)+'\\n')\n",
    "    f.write(getsource(inspect_adaline.fit)+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40754109",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    ุจุฑุง ุณุงุฎุชูโุดุฏู ูุงู <code>result.zip</code> ุณููู ุฒุฑ ุฑุง ุงุฌุฑุง ฺฉูุฏ. ุชูุฌู ุฏุงุดุชู ุจุงุดุฏ ฺฉู ูพุด ุงุฒ ุงุฌุฑุง ุณููู ุฒุฑ ุชุบุฑุงุช ุงุนูุงู ุดุฏู ุฏุฑ ูุชโุจูฺฉ ุฑุง ุฐุฎุฑู ฺฉุฑุฏู ุจุงุดุฏ (<code>ctrl+s</code>) ุชุง ุฏุฑ ุตูุฑุช ูุงุฒ ุจู ูพุดุชุจุงู ุงูฺฉุงู ุจุฑุฑุณ ฺฉุฏ ุดูุง ูุฌูุฏ ุฏุงุดุชู ุจุงุดุฏ.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c3bcd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['df1.csv', 'df2.csv', 'df3.csv', 'perceptron.ipynb', 'Perceptron.py', 'Adaline.py', 'linearly_separable.json']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import joblib\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "file_names = ['df1.csv', 'df2.csv', 'df3.csv', 'perceptron.ipynb', 'Perceptron.py', 'Adaline.py', 'linearly_separable.json']\n",
    "compress(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c917b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qenv",
   "language": "python",
   "name": "qenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
