{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d333515a",
   "metadata": {},
   "source": [
    "<h1 align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "پرسپترون\n",
    "</font>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed20bff",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "مقدمه و صورت مسئله\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    به یک تمرین اساسی از پایه‌ای‌ترین مباحث شبکه‌های عصبی خوش آمدید! در این تمرین رویکرد متفاوتی را در پیش خواهیم گرفت و قصد داریم ساختار پرسپترون و الگوریتم آموزش آن را که در درسنامه‌های پیشین آموختید مستقیماً پیاده‌سازی کنیم. کدنویسی در این سطح به شما کمک خواهد کرد که به شکل عملی درک عمیق‌تری از نحوه‌ی کار این مدل پیدا کنید و در آینده نیز هنگام مواجه با مدل‌های مختلف شبکه‌های عصبی قادر به تحلیل آسان‌تر ساختار آن‌ها باشید. پس از طراحی پرسپترون، آن را روی مجموعه‌داده‌ی مشهور <i>گل‌های زنبق (iris)</i> آموزش داده و عملکرد دو روش مختلف آموزش پرسپترون، یعنی قاعده‌ی پرسپترون و قاعده‌ی دلتا را بر روی این مجموعه‌داده ارزیابی خواهیم کرد.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af1784",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "وارد کردن کتابخانه‌های مورد نیاز\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    ابتدا کتابخانه‌های مورد نیازتان را وارد کنید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99450f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amin/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from inspect import getsource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72faaed8",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "معرفی مجموعه‌داده\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "در این تمرین از مجموعه‌‌داده‌ی ساده اما مشهور گل‌های زنبق (iris) استفاده خواهیم کرد. این مجموعه‌داده شامل سه دسته (نوع گیاه) است که از هر دسته 50 نمونه داده وجود دارد. هر داده دارای یک برچسب و چهار ویژگی است که در جدول زیر معرفی شده‌اند.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|ستون|توضیحات|\n",
    "|:------:|:---:|\n",
    "|SepalLengthCm|طول کاسبرگ (سانتی‌متر)|\n",
    "|SepalWidthCm|عرض کاسبرگ (سانتی‌متر)|\n",
    "|PetalLengthCm|طول گلبرگ (سانتی‌متر)|\n",
    "|PetalWidthCm|عرض گلبرگ (سانتی‌متر)|\n",
    "|Species|نوع گیاه (متغیر هدف)|\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99bbe9b",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "خواندن مجموعه داده\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    در ابتدا نیاز است فایل‌ مجموعه‌داده را بخوانید. برای این تمرین مجموعه‌ی آزمونی در نظر گرفته نشده و هدف تنها پیاده‌سازی و تحلیل مدل است. بنابراین کل مجموعه‌داده را می‌توانید از فایل <code>iris.csv</code> موجود در پوشه‌ی مسئله خوانده و از نمونه‌های موجود در آن برای آموزش پرسپترون استفاده کنید. توجه داشته باشید که نیازی به ستون <code>Id</code> ندارید و می‌توانید آن را از دیتافریم خود حذف کنید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dcb9e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('../data/iris.csv') # To-Do\n",
    "train_data.drop(columns=['Id'], inplace=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1617a7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Species'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23daec54",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "پیش‌پردازش و مهندسی ویژگی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    اگر به مقادیر ستون <code>Species</code> نگاه کرده باشید، دریافته‌اید که این مجموعه‌داده دارای سه کلاس <code>Iris-setosa</code> ،<code>Iris-versicolor</code> و <code>Iris-virginica</code> است.\n",
    "    <br>\n",
    "    از آنجا که یک پرسپترون واحد قادر به دسته‌بندی دوکلاسه هست در این تمرین قصد داریم سه مدل مختلف را آموزش دهیم که هرکدام از آن‌ها بین یک ترکیب دوتایی از سه دسته ممکن تصمیم‌گیری می‌کند. یعنی قرار است تا سه پرسپترون را به شکل زیر آموزش دهیم:\n",
    "</font>\n",
    "</p>\n",
    "<ul dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    <li>تصمیم‌گیری بین دو دسته‌ی <code>Iris-setosa</code> و <code>Iris-versicolor</code></li>\n",
    "    <li>تصمیم‌گیری بین دو دسته‌ی <code>Iris-setosa</code> و <code>Iris-virginica</code></li>\n",
    "    <li>تصمیم‌گیری بین دو دسته‌ی <code>Iris-versicolor</code> و <code>Iris-virginica</code></li>\n",
    "</font>\n",
    "</ul>\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    این امر همچنین به ما کمک می‌کند تا به‌صورت تجربی کشف کنیم که کدام دسته از سایر دسته‌ها به‌صورت خطی تفکیک‌پذیر است.\n",
    "</font>\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    بنابراین از شما خواسته می‌شود که دیتافریم اصلی را به سه دیتافریم کوچک‌تر (با نام‌های <code>df2</code> ،<code>df1</code> و <code>df3</code>) تقسیم کنید، به شکلی که در هر دیتافریم تنها نمونه‌های مربوط به یکی از حالت‌های لیست بالا وجود داشته باشد. به عنوان مثال در دیتافریم نخست یعنی <code>df1</code> تنها نمونه‌های حالت اول یعنی دسته‌های <code>Iris-setosa</code> و <code>Iris-versicolor</code> وجود داشته باشد.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7c23000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm          Species\n",
       "50             7.0           3.2            4.7           1.4  Iris-versicolor\n",
       "51             6.4           3.2            4.5           1.5  Iris-versicolor\n",
       "52             6.9           3.1            4.9           1.5  Iris-versicolor\n",
       "53             5.5           2.3            4.0           1.3  Iris-versicolor\n",
       "54             6.5           2.8            4.6           1.5  Iris-versicolor\n",
       "..             ...           ...            ...           ...              ...\n",
       "145            6.7           3.0            5.2           2.3   Iris-virginica\n",
       "146            6.3           2.5            5.0           1.9   Iris-virginica\n",
       "147            6.5           3.0            5.2           2.0   Iris-virginica\n",
       "148            6.2           3.4            5.4           2.3   Iris-virginica\n",
       "149            5.9           3.0            5.1           1.8   Iris-virginica\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = train_data[(train_data.Species == 'Iris-setosa') | (train_data.Species == 'Iris-versicolor')] # To-Do\n",
    "\n",
    "df2 = train_data[(train_data.Species == 'Iris-setosa') | (train_data.Species == 'Iris-virginica')]  # To-Do\n",
    "\n",
    "df3 = train_data[(train_data.Species == 'Iris-versicolor') | (train_data.Species == 'Iris-virginica')] # To-Do\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0927d1",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "کد زیر دیتافریم‌های شما را ذخیره می‌کند تا در انتهای نت‌بوک به فایل جواب شما اضافه شود. سه دیتافریم بالا از نظر تعداد نمونه، ستون‌ها و مقادیر موجود در ستون <code>Species</code> داوری خواهند شد. نیازی به تغییر کد نیست و کافیست تنها سلول را اجرا نمایید.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "704751ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('df1.csv', index=False)\n",
    "df2.to_csv('df2.csv', index=False)\n",
    "df3.to_csv('df3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0923ecf5",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    اکنون اگر قصد دارید می‌توانید پیش‌پردازش‌های دلخواه خود را بر روی مقادیر ویژگی‌ها انجام دهید. همچنین توجه داشته باشید مقادیر ستون برچسب را باید به شکل اعداد <code dir=ltr>+1</code> و <code dir=ltr>-1</code> کدگذاری کنید. علاوه بر این فراموش نکنید که ستون‌های ویژگی را از ستون متغیر هدف (برچسب) جدا کنید.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f493320e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amin/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/generic.py:6619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "# To-Do\n",
    "df1['Species'].replace({'Iris-setosa': -1, 'Iris-versicolor': +1}, inplace=True)\n",
    "df2['Species'].replace({'Iris-setosa': -1, 'Iris-virginica': +1}, inplace=True)\n",
    "df3['Species'].replace({'Iris-versicolor': -1, 'Iris-virginica': +1}, inplace=True)\n",
    "\n",
    "df1_features = df1.drop(columns=['Species'])\n",
    "df1_target = df1['Species'] \n",
    "\n",
    "df2_features = df1.drop(columns=['Species'])\n",
    "df2_target = df1['Species'] \n",
    "\n",
    "df3_features = df1.drop(columns=['Species'])\n",
    "df3_target = df1['Species'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f2c94",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "مدل‌سازی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    اکنون که داده‌ها را پردازش و آماده کردید نوبت به قسمت اصلی یعنی مدل می‌رسد. همانطور که در ابتدا ذکر کردیم در این تمرین دیگر خبری از کتابخانه‌ی آماده‌ی <code>scikit-learn</code> نیست. در اینجا از شما خواسته شده تا یک مدل ساده‌ی پرسپترون را به دو حالت (قاعده‌ی پرسپترون و قاعده‌ی دلتا) از صفر پیاده کنید. برای این کار قدم به قدم هر جزء این مدل را شرح خواهیم داد تا نسبت به پیاده‌‌سازی آن اقدام کنید.\n",
    "    <br>\n",
    "    <b>نکته: </b>\n",
    "    در اعمال ریاضی و محاسباتی خود تنها از کتابخانه‌ی نامپای استفاده کنید و لیست‌های خود را نیز به شکل آرایه‌ی نامپای تعریف کنید.\n",
    "    <br>\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23321043",
   "metadata": {},
   "source": [
    "<h3 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "قاعده‌ی پرسپترون\n",
    "</font>\n",
    "</h3>\n",
    "<center>\n",
    "    <img src=\"perceptron_rule.png\">\n",
    "<center>\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "    به منظور پیاده‌سازی مدل،‌ کلاسی با نام <code>Perceptron</code> تعریف خواهیم کرد که در هنگام ساخته شدن (<code>__init__</code>) یک ویژگی مرتبط با وزن‌ها را با نام <code>weights</code> به این کلاس اضافه می‌کند. بنابراین در هنگام پیاده‌سازی توابع جهت دسترسی به وزن‌های پرسپترون می‌توانید از <code>self.weights</code> استفاده کنید.\n",
    "    <br>\n",
    "    اکنون هرکدام از توابع مورد نیاز این کلاس را شرح خواهیم داد تا شما به پیاده‌سازی آن‌ها بپردازید:\n",
    "    <br>\n",
    "    <ul dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "        <li>\n",
    "        تابع <code>weighting</code> مقادیر ویژگی‌های یک نمونه را گرفته و آن را در بردار وزن ضرب نقطه‌ای می‌کند. سپس ورودی وزن‌دار شده به عنوان خروجی برگردانده می‌شود.\n",
    "        </li>\n",
    "        <li>\n",
    "        در تابعی به نام <code>activation</code> تابع فعال‌ساز را که در اینجا تابع علامت است پیاده خواهیم کرد. این تابع، ورودی وزن‌دار را گرفته و در صورتیکه حاصل بیشتر یا مساوی صفر بود خروجی <code>1</code> و در غیر این‌صورت خروجی <code dir=ltr>-1</code> تولید می‌کند.\n",
    "        </li>\n",
    "        <li>\n",
    "        تابع <code>predict</code> آرایه‌ای از نمونه‌ها را گرفته و آرایه‌ای شامل برچسب پیش‌بینی‌شده برای هرکدام از نمونه‌ها را بر می‌گرداند. در این تابع باید به ازای هر نمونه ابتدا آن را به کمک تابع <code>weighting</code> وزن دار کنید و حاصل را به تابع <code>activation</code> بدهید تا برچسب <code dir=ltr>+1</code> یا <code dir=ltr>-1</code> را برای نمونه تولید کند.\n",
    "        </li>\n",
    "        <li>\n",
    "        الگوریتم اصلی پرسپترون در واقع در تابع <code>fit</code> پیاده می‌شود. این تابع ورودی‌ها و هایپرپارامترهای زیر را گرفته و سپس طبق مراحلی که شرح خواهیم داد شروع به آموزش [وزن‌های] پرسپترون می‌کند.\n",
    "        </li>\n",
    "    </ul>\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|ورودی|توضیحات|\n",
    "|:------:|:---:|\n",
    "|inputs|ویژگی‌های ورودی نمونه‌های آموزشی|\n",
    "|outputs|متغیر هدف (برچسب) نمونه‌‌های آموزشی|\n",
    "|learning_rate|نرخ یادگیری (η)|\n",
    "|epochs|تعداد دفعات آموزش بر روی تمام نمونه‌ها|\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium; padding-right:40px;\">\n",
    "<font face=\"vazir\">\n",
    "در درسنامه‌ی پرسپترون اشاره کردیم که عبارت بایاس را می‌توان به کمک اضافه کردن یک ورودی ثابت <code>1</code> به ویژگی‌های ورودی تعبیه کرد. بنابراین در تابع <code>fit</code> ابتدا به اول ویژگی‌های هرکدام از نمونه‌ها عدد <code>1</code> را اضافه کنید (به عنوان مثال برای نمونه‌ی <code>inputs[i]</code>، باید <code>inputs[i][0]</code> برابر <code>1</code> باشد). با این کار یک واحد به طول بردار ویژگی نمونه‌ها اضافه خواهد شد. (فراموش نکنید که این کار را در هنگام پیش‌بینی یعنی تابع predict نیز باید انجام دهید.)\n",
    "<br>\n",
    "پس از آن نیاز است تا بردار وزن یعنی <code>self.weights</code> را ساخته و مقداردهی کنید. برای مقداردهی اولیه می‌توانید از اعداد تصادفی بین <code dir=ltr>0</code> تا <code dir=ltr>1</code> استفاده کنید.\n",
    "<br>\n",
    "سپس در یک حلقه به ازای هر دور (به تعداد <code>epochs</code>) باید یک‌بار کل مجموعه‌ی آموزشی را بررسی کنید. بنابراین در داخل این حلقه، یک حلقه‌ی دیگر خواهید داشت که هربار یکی از نمونه‌ها را بررسی می‌کند (به دلیل استفاده از روش کاهش گرادیان تصادفی در هر تکرار تنها یک نمونه بررسی و وزن‌ها آپدیت می‌شوند).\n",
    "<br>\n",
    "به ازای هر نمونه، ابتدا به کمک تابع <code>weighting</code> بردار ویژگی آن را در بردار وزن ضرب نقطه‌ای می‌کنیم تا ورودی وزن‌دار به دست آید. سپس حاصل به‌دست‌آمده را به تابع فعال‌سازی می‌دهیم تا مقدار خروجی مدل را تولید کند. حال با تفریق پیش‌بینی مدل از مقدار (برچسب) واقعی می‌توانیم اختلاف‌شان را به دست آوریم. سپس طبق فرمول‌های معرفی‌شده در درسنامه، با ضرب این اختلاف در نرخ یادگیری و ویژگی‌های ورودی و سپس جمع آن با مقادیر قبلی بردار وزن می‌توانیم به آپدیت بردار وزن بپردازیم.\n",
    "<br>\n",
    "پیشنهاد می‌شود در آخر هر دور نسبت به چاپ دقت مدل کنونی بر روی مجموعه‌ی آموزشی نیز اقدام کنید. برای این کار کافیست نمونه‌ها را به تابع <code>predict</code> بدهید تا پیش‌بینی مدل تولید شود و سپس به کمک تابع آماده‌ی <code>accuracy_score</code> دقت آن را به دست آورید.\n",
    "<br>\n",
    "<b>نکته: </b>\n",
    "در هیچ‌کدام از توابع خود به غیر از تابع <code>fit</code> چیزی را چاپ (<code>print</code>) نکنید، در غیر این‌صورت سیستم داوری قادر به امتیازدهی به توابع شما نخواهد بود.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "231cd2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "\n",
    "    def weighting(self, input):\n",
    "        weighted_sum = np.dot(input, self.weights)\n",
    "        return weighted_sum # To-Do\n",
    "\n",
    "    def activation(self, weighted_input):\n",
    "        if weighted_input >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1 # To-Do\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        # adding a 1 to the first position of each input (adding the bias term)\n",
    "        new_inputs = np.insert(inputs, 0, 1, axis=1)# To-Do\n",
    "        # a list of final prediction for each test sample\n",
    "        predictions = []\n",
    "        for input in new_inputs:\n",
    "            weighted_input = self.weighting(input)# To-Do\n",
    "            prediction = self.activation(weighted_input)# To-Do\n",
    "            predictions.append(prediction)\n",
    "        # converting the list to a numpy array\n",
    "        predictions = np.array(predictions)\n",
    "        return predictions\n",
    "\n",
    "    def fit(self, inputs, outputs, learning_rate=0.1, epochs=64):\n",
    "        # adding a 1 to the first position of each input (adding the bias term)\n",
    "        new_inputs = np.insert(inputs, 0, 1, axis=1) # To-Do\n",
    "        # initializing the weights\n",
    "        self.weights = np.random.rand(new_inputs.shape[1])\n",
    "        # training loop\n",
    "        for epoch in range(epochs):\n",
    "            for sample, target in zip(new_inputs, outputs):\n",
    "                weighted_input = self.weighting(sample)# To-Do (using self.weighting on sample)\n",
    "                pred = self.activation(weighted_input)\n",
    "                diff =  target - pred# To-Do (based on target and self.activation)\n",
    "                self.weights += diff * learning_rate * sample # To-Do (based on self.weights, learning_rate, diff and sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a46903",
   "metadata": {},
   "source": [
    "<h4 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "آموزش مدل\n",
    "</font>\n",
    "</h4>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "    پس از طراحی ساختار پرسپترون می‌توانید به کمک <code dir=ltr>Perceptron()</code> ابتدا یک نمونه از این کلاس بسازید و سپس تابع <code>fit</code> را با آرگومان‌های مناسب صدا بزنید تا آموزش مدل آغاز شود. این کار را برای هر سه حالت ورودی انجام دهید. پیشنهاد می‌شود مقادیر مختلف نرخ یادگیری مانند 0.1، 0.01، 0.001 و... را آزمایش و مقایسه کنید.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4f7297d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (100, 5), indices imply (100, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m perceptron \u001b[39m=\u001b[39m Perceptron()\n\u001b[0;32m----> 2\u001b[0m perceptron\u001b[39m.\u001b[39;49mfit(df1_features, df1_target) \u001b[39m# To-Do\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[36], line 31\u001b[0m, in \u001b[0;36mPerceptron.fit\u001b[0;34m(self, inputs, outputs, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, inputs, outputs, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m):\n\u001b[1;32m     30\u001b[0m     \u001b[39m# adding a 1 to the first position of each input (adding the bias term)\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     new_inputs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49minsert(inputs, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39m# To-Do\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[39m# initializing the weights\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(new_inputs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36minsert\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/numpy/lib/function_base.py:5357\u001b[0m, in \u001b[0;36minsert\u001b[0;34m(arr, obj, values, axis)\u001b[0m\n\u001b[1;32m   5355\u001b[0m     new[\u001b[39mtuple\u001b[39m(slobj)] \u001b[39m=\u001b[39m arr[\u001b[39mtuple\u001b[39m(slobj2)]\n\u001b[1;32m   5356\u001b[0m     \u001b[39mif\u001b[39;00m wrap:\n\u001b[0;32m-> 5357\u001b[0m         \u001b[39mreturn\u001b[39;00m wrap(new)\n\u001b[1;32m   5358\u001b[0m     \u001b[39mreturn\u001b[39;00m new\n\u001b[1;32m   5359\u001b[0m \u001b[39melif\u001b[39;00m indices\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m   5360\u001b[0m     \u001b[39m# Can safely cast the empty list to intp\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/generic.py:2025\u001b[0m, in \u001b[0;36mNDFrame.__array_wrap__\u001b[0;34m(self, result, context)\u001b[0m\n\u001b[1;32m   2022\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_axes_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_AXIS_ORDERS, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2023\u001b[0m \u001b[39m# error: Argument 1 to \"NDFrame\" has incompatible type \"ndarray\";\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m \u001b[39m# expected \"BlockManager\"\u001b[39;00m\n\u001b[0;32m-> 2025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_constructor(res, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49md)\u001b[39m.\u001b[39m__finalize__(  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m     \u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m__array_wrap__\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2027\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/frame.py:672\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    662\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    663\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    664\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    669\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    670\u001b[0m         )\n\u001b[1;32m    671\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 672\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    673\u001b[0m             data,\n\u001b[1;32m    674\u001b[0m             index,\n\u001b[1;32m    675\u001b[0m             columns,\n\u001b[1;32m    676\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    677\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    678\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    679\u001b[0m         )\n\u001b[1;32m    681\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/internals/construction.py:324\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    320\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    321\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    322\u001b[0m )\n\u001b[0;32m--> 324\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    326\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    328\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/internals/construction.py:393\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    391\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    392\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> 393\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (100, 5), indices imply (100, 4)"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(df1_features, df1_target) # To-Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e48be138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-500.03652508,  277.07236665, -146.17454133,  133.4052457 ,\n",
       "        100.4345656 ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(df2_features, df2_target, 0.1, 10) # To-Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e1c9f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-499.89779564, -341.50292081,  426.70810698,  133.559198  ,\n",
       "        100.0580591 ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(df3_features, df3_target, 0.1, 10) # To-Do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d87e34",
   "metadata": {},
   "source": [
    "<h4 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "🤔\n",
    "پرسش\n",
    "</font>\n",
    "</h4>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "    از میان سه حالت مختلفی که برای کلاس‌های مجموعه‌داده در نظر گرفتیم، یک یا چند حالت به‌صورت خطی تفکیک‌پذیر هستند. تفکیک‌پذیر خطی بودن آن‌ها را می‌توان طبق دقت به‌دست‌آمده توسط مدل نتیجه‌گیری کرد. طبق نتایج به‌دست‌آمده در اجرای خود فکر می‌کنید کدام حالت یا حالت‌ها به‌صورت خطی تفکیک‌پذیر هستند؟ پاسخ را در متغیر <code>linearly_separable</code> به شکل یک لیست وارد کنید. به عنوان مثال اگر پاسخ شما حالت اول یعنی کلاس‌های <code>Iris-setosa</code> و <code>Iris-versicolor</code> است آنگاه <code>linearly_separable</code> را به‌صورت <code>[1]</code> و اگر پاسخ شما مثلاً حالت دوم و سوم است آن را به شکل <code dir=ltr>[2, 3]</code> مقداردهی کنید.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9c9053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linearly_separable = [1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b86c670",
   "metadata": {},
   "source": [
    "<h3 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "قاعده‌ی دلتا\n",
    "</font>\n",
    "</h3>\n",
    "<center>\n",
    "<img src=\"delta_rule.png\">\n",
    "</center>\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "    در این حالت می‌خواهیم کلاسی با نام <code>Adaline</code> بسازیم و  مدل را با قاعده‌ی دلتا آموزش دهیم. در اینجا از روش نزول گرادیان استفاده خواهیم کرد، یعنی تمام نمونه‌های آموزشی به‌صورت همزمان بر روی آپدیت وزن تاثیر می‌گذارند (برخلاف روش نزول گرادیان تصادفی که هربار یک نمونه دیده می‌شد). کد این مدل بسیار شبیه به حالت قبلی خواهد بود و تنها نیاز است چند مورد جزئی زیر را اعمال کنید:\n",
    "    <br>\n",
    "    <ul dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "        <li>\n",
    "        از آنجا که در این حالت از تابع فعال‌سازی خطی استفاده می‌شود تابع <code>activation</code> تنها همان ورودی وزن‌دار خود را بدون هیچ‌گونه تغییری خروجی می‌دهد.\n",
    "        </li>\n",
    "        <li>\n",
    "        در تابع <code>prediction</code> پس از وزن‌دار کردن و عبور از تابع فعال‌سازی، باید بررسی کنید که اگر حاصل بزرگتر یا مساوی صفر بود، مقدار پیش‌بینی <code dir=ltr>+1</code> و در غیر این‌صورت <code dir=ltr>-1</code> شود.\n",
    "        </li>\n",
    "        <li>\n",
    "        پیشنهاد می‌شود به جای اینکه یک حلقه بنویسید که خطای هر نمونه را محاسبه کند و در آخر از مجموع آن جهت آپدیت وزن استفاده کنید، همین کار را به‌صورت برداری انجام دهید (با ضرب نقطه‌ای ترانهاده‌ی ماتریس ورودی در بردار وزن).\n",
    "        </li>\n",
    "    </ul>\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7961eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "\n",
    "    def weighting(self, input):\n",
    "        weighted_sum = np.dot(input, self.weights)\n",
    "        return weighted_sum # To-Do\n",
    "\n",
    "    def activation(self, weighted_input):\n",
    "        return weighted_input # To-Do\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        # adding a 1 to the first position of each input (adding the bias term)\n",
    "        new_inputs = np.insert(inputs, 0, 1, axis=1)# To-Do\n",
    "        # a list of final prediction for each test sample\n",
    "        predictions = []\n",
    "        for input in new_inputs:\n",
    "            weighted_input = self.weighting(input)# To-Do\n",
    "            prediction = self.activation(weighted_input)# To-Do\n",
    "            if prediction >= 0:\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(-1)\n",
    "        # converting the list to a numpy array\n",
    "        predictions = np.array(predictions)\n",
    "        return predictions\n",
    "\n",
    "    def fit(self, inputs, outputs, learning_rate=0.1, epochs=64):\n",
    "        # adding a 1 to the first position of each input (adding the bias term)\n",
    "        new_inputs = np.insert(inputs, 0, 1, axis=1) # To-Do\n",
    "        # initializing the weights\n",
    "        self.weights = np.random.rand(new_inputs.shape[1])\n",
    "        # training loop\n",
    "        for epoch in range(epochs):\n",
    "            for sample, target in zip(new_inputs, outputs):\n",
    "                weighted_input = self.weighting(sample)# To-Do (using self.weighting on sample)\n",
    "                pred = self.activation(weighted_input)\n",
    "                diff =  target - pred# To-Do (based on target and self.activation)\n",
    "                self.weights += diff * learning_rate * sample # To-Do (based on self.weights, learning_rate, diff and sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25901f4f",
   "metadata": {},
   "source": [
    "<h4 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "آموزش مدل\n",
    "</font>\n",
    "</h4>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "    پس از طراحی ساختار پرسپترون می‌توانید به کمک <code dir=ltr>Adaline()</code> ابتدا یک نمونه از این کلاس بسازید و سپس تابع <code>fit</code> را با آرگومان‌های مناسب صدا بزنید تا آموزش مدل آغاز شود. این کار را برای هر سه حالت ورودی انجام دهید. پیشنهاد می‌شود مقادیر مختلف نرخ یادگیری مانند 0.1، 0.01، 0.001 و... را آزمایش و مقایسه کنید.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "008fcefd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (100, 5), indices imply (100, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m adaline \u001b[39m=\u001b[39m Adaline()\n\u001b[0;32m----> 2\u001b[0m adaline\u001b[39m.\u001b[39;49mfit(df1_features, df1_target) \u001b[39m# To-Do\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 31\u001b[0m, in \u001b[0;36mAdaline.fit\u001b[0;34m(self, inputs, outputs, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, inputs, outputs, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m):\n\u001b[1;32m     30\u001b[0m     \u001b[39m# adding a 1 to the first position of each input (adding the bias term)\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     new_inputs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49minsert(inputs, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39m# To-Do\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[39m# initializing the weights\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(new_inputs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36minsert\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/numpy/lib/function_base.py:5357\u001b[0m, in \u001b[0;36minsert\u001b[0;34m(arr, obj, values, axis)\u001b[0m\n\u001b[1;32m   5355\u001b[0m     new[\u001b[39mtuple\u001b[39m(slobj)] \u001b[39m=\u001b[39m arr[\u001b[39mtuple\u001b[39m(slobj2)]\n\u001b[1;32m   5356\u001b[0m     \u001b[39mif\u001b[39;00m wrap:\n\u001b[0;32m-> 5357\u001b[0m         \u001b[39mreturn\u001b[39;00m wrap(new)\n\u001b[1;32m   5358\u001b[0m     \u001b[39mreturn\u001b[39;00m new\n\u001b[1;32m   5359\u001b[0m \u001b[39melif\u001b[39;00m indices\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m   5360\u001b[0m     \u001b[39m# Can safely cast the empty list to intp\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/generic.py:2025\u001b[0m, in \u001b[0;36mNDFrame.__array_wrap__\u001b[0;34m(self, result, context)\u001b[0m\n\u001b[1;32m   2022\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_axes_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_AXIS_ORDERS, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2023\u001b[0m \u001b[39m# error: Argument 1 to \"NDFrame\" has incompatible type \"ndarray\";\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m \u001b[39m# expected \"BlockManager\"\u001b[39;00m\n\u001b[0;32m-> 2025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_constructor(res, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49md)\u001b[39m.\u001b[39m__finalize__(  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m     \u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m__array_wrap__\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2027\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/frame.py:672\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    662\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    663\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    664\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    669\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    670\u001b[0m         )\n\u001b[1;32m    671\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 672\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    673\u001b[0m             data,\n\u001b[1;32m    674\u001b[0m             index,\n\u001b[1;32m    675\u001b[0m             columns,\n\u001b[1;32m    676\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    677\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    678\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    679\u001b[0m         )\n\u001b[1;32m    681\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/internals/construction.py:324\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    320\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    321\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    322\u001b[0m )\n\u001b[0;32m--> 324\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    326\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    328\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/Jump Machine Learning/qenv/lib/python3.9/site-packages/pandas/core/internals/construction.py:393\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    391\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    392\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> 393\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (100, 5), indices imply (100, 4)"
     ]
    }
   ],
   "source": [
    "adaline = Adaline()\n",
    "adaline.fit(df1_features, df1_target) # To-Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75920d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5009/1789267452.py:32: RuntimeWarning: invalid value encountered in add\n",
      "  self.weights += dif *(learning_rate * inputs[j, :])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaline = Adaline()\n",
    "adaline.fit(df2_features, df2_target) # To-Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "598042ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5009/1789267452.py:32: RuntimeWarning: invalid value encountered in add\n",
      "  self.weights += dif *(learning_rate * inputs[j, :])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaline = Adaline()\n",
    "adaline.fit(df3_features, df3_target) # To-Do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08def517",
   "metadata": {},
   "source": [
    "<h4 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "💭\n",
    "تفکر\n",
    "</font>\n",
    "</h4>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "    مقایسه‌ی عملکرد دو مدل <code>Perceptron</code> و <code>Adaline</code> در حالتی که مجموعه‌داده به شکل خطی تفکیک‌پذیر نباشد می‌تواند به شکل عملی تفاوت میان این دو مدل را برای‌تان شفاف سازد.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09c5f3",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>داوری</b>\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "در این تمرین هرکدام از توابعی که پیاده کرده‌اید به‌صورت جداگانه مورد داوری قرار خواهد گرفت تا از عملکرد هرکدام به شکل جداگانه مطمئن شوید. البته تابع <code>fit</code> هر کلاس به منزله‌ی عملکرد کلی مدل است و جهت ارزیابی، مدل شما بر روی یک حالت تفکیک‌پذیر خطی از مجموعه‌داده iris آموزش خواهد دید و انتظار می‌رود که بتواند دقت تقریبی ۱۰۰ درصد را بر روی مجموعه‌ی آموزشی به دست آورد. علاوه بر این دیتافریم‌های اولیه و پاسخ شما به پرسش مطرح‌شده درباره‌ی تفکیک‌پذیری خطی نیز امتیازدهی خواهد شد.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a77e7cd",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>سلول جواب‌ساز</b>\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    سلول‌های زیر را به منظور ساخت فایل‌های کلاس‌های پیاده‌سازی شده و پاسخ خود به پرسش مطرح شده اجرا نمایید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e847dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"linearly_separable.json\", \"w\") as f:\n",
    "    json.dump(linearly_separable, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e18c2ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_perceptron = Perceptron()\n",
    "with open(\"Perceptron.py\", \"w\") as f:\n",
    "    f.write('import numpy as np\\n')\n",
    "    f.write('from sklearn.metrics import accuracy_score\\n')\n",
    "    f.write('class Perceptron:\\n')\n",
    "    f.write(getsource(inspect_perceptron.__init__)+'\\n')\n",
    "    f.write(getsource(inspect_perceptron.weighting)+'\\n')\n",
    "    f.write(getsource(inspect_perceptron.activation)+'\\n')\n",
    "    f.write(getsource(inspect_perceptron.predict)+'\\n')\n",
    "    f.write(getsource(inspect_perceptron.fit)+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "233b9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_adaline = Adaline()\n",
    "with open(\"Adaline.py\", \"w\") as f:\n",
    "    f.write('import numpy as np\\n')\n",
    "    f.write('from sklearn.metrics import accuracy_score\\n')\n",
    "    f.write('class Adaline:\\n')\n",
    "    f.write(getsource(inspect_adaline.__init__)+'\\n')\n",
    "    f.write(getsource(inspect_adaline.weighting)+'\\n')\n",
    "    f.write(getsource(inspect_adaline.activation)+'\\n')\n",
    "    f.write(getsource(inspect_adaline.predict)+'\\n')\n",
    "    f.write(getsource(inspect_adaline.fit)+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40754109",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    برای ساخته‌شدن فایل <code>result.zip</code> سلول زیر را اجرا کنید. توجه داشته باشید که پیش از اجرای سلول زیر تغییرات اعمال شده در نت‌بوک را ذخیره کرده باشید (<code>ctrl+s</code>) تا در صورت نیاز به پشتیبانی امکان بررسی کد شما وجود داشته باشد.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c3bcd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['df1.csv', 'df2.csv', 'df3.csv', 'perceptron.ipynb', 'Perceptron.py', 'Adaline.py', 'linearly_separable.json']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import joblib\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "file_names = ['df1.csv', 'df2.csv', 'df3.csv', 'perceptron.ipynb', 'Perceptron.py', 'Adaline.py', 'linearly_separable.json']\n",
    "compress(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c917b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qenv",
   "language": "python",
   "name": "qenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
